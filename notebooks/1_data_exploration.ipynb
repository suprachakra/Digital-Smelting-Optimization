{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Exploration & Cleaning\n",
    "\n",
    "This notebook demonstrates basic data ingestion, cleaning, and transformation for the MetalX Smelting project."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='whitegrid')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "RAW_DATA_PATH = '../data/raw/'\n",
    "PROCESSED_DATA_PATH = '../data/processed/'\n",
    "\n",
    "filenames = ['sensor_data_day1.csv', 'sensor_data_day2.csv']\n",
    "\n",
    "# Load multiple CSVs into a single DataFrame or keep separate\n",
    "df_list = []\n",
    "for fname in filenames:\n",
    "    fpath = os.path.join(RAW_DATA_PATH, fname)\n",
    "    temp_df = pd.read_csv(fpath, parse_dates=['timestamp'])\n",
    "    df_list.append(temp_df)\n",
    "\n",
    "raw_data = pd.concat(df_list, ignore_index=True)\n",
    "raw_data.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Basic Exploration\n",
    "\n",
    "- Check for missing values\n",
    "- Describe statistical distribution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print('Missing values per column:')\n",
    "print(raw_data.isna().sum())\n",
    "\n",
    "print('\\nStatistical summary:')\n",
    "display(raw_data.describe())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Detect Outliers (Naive Approach)\n",
    "We'll assume outliers if voltage/current/temperature deviate significantly from the mean.\n",
    "\n",
    "> Note: In a real environment, you'd have domain-specific thresholds or advanced anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Let's define a simple function for outlier detection\n",
    "def mark_outliers(df, col, z_thresh=2.5):\n",
    "    mean_val = df[col].mean()\n",
    "    std_val = df[col].std()\n",
    "    cutoff_upper = mean_val + z_thresh * std_val\n",
    "    cutoff_lower = mean_val - z_thresh * std_val\n",
    "    return (df[col] < cutoff_lower) | (df[col] > cutoff_upper)\n",
    "\n",
    "# Make a copy\n",
    "clean_data = raw_data.copy()\n",
    "clean_data['is_outlier'] = False\n",
    "\n",
    "for c in ['voltage', 'current', 'temperature']:\n",
    "    outlier_mask = mark_outliers(clean_data, c, z_thresh=2.5)\n",
    "    clean_data.loc[outlier_mask, 'is_outlier'] = True\n",
    "\n",
    "print(f\"Total outliers found: {clean_data['is_outlier'].sum()}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Remove or Keep Outliers?\n",
    "For demonstration, we'll keep them but flagged. In a real pipeline, you might remove them or handle them case-by-case."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Let's quickly visualize distributions\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i, c in enumerate(['voltage', 'current', 'temperature']):\n",
    "    sns.histplot(data=clean_data, x=c, hue='is_outlier', ax=axs[i], kde=True)\n",
    "    axs[i].set_title(f\"Distribution of {c}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Save Processed Data\n",
    "We'll split them back by day to mimic a daily pipeline run."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Filter data by day\n",
    "day1 = clean_data[clean_data['timestamp'].dt.day == 1]\n",
    "day2 = clean_data[clean_data['timestamp'].dt.day == 2]\n",
    "\n",
    "day1_path = os.path.join(PROCESSED_DATA_PATH, 'sensor_data_day1_cleaned.csv')\n",
    "day2_path = os.path.join(PROCESSED_DATA_PATH, 'sensor_data_day2_cleaned.csv')\n",
    "\n",
    "day1.to_csv(day1_path, index=False)\n",
    "day2.to_csv(day2_path, index=False)\n",
    "\n",
    "print('Processed data saved successfully!')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

